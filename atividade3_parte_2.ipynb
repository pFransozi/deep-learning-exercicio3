{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hGHcKpMaeOYw",
        "outputId": "6feeb3fb-b12c-4ea8-a0f1-9efa9e12604e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (2.1.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorflow in ./.venv/lib/python3.10/site-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in ./.venv/lib/python3.10/site-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./.venv/lib/python3.10/site-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from tensorflow) (80.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in ./.venv/lib/python3.10/site-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.10/site-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (2.1.3)\n",
            "Requirement already satisfied: h5py>=3.11.0 in ./.venv/lib/python3.10/site-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in ./.venv/lib/python3.10/site-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.venv/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in ./.venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in ./.venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in ./.venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (1.7.0)\n",
            "Requirement already satisfied: numpy>=1.22.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (2.1.3)\n",
            "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: matplotlib in ./.venv/lib/python3.10/site-packages (3.10.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.10/site-packages (from matplotlib) (2.1.3)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scikit-image in ./.venv/lib/python3.10/site-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in ./.venv/lib/python3.10/site-packages (from scikit-image) (2.1.3)\n",
            "Requirement already satisfied: scipy>=1.11.4 in ./.venv/lib/python3.10/site-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.10/site-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in ./.venv/lib/python3.10/site-packages (from scikit-image) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in ./.venv/lib/python3.10/site-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in ./.venv/lib/python3.10/site-packages (from scikit-image) (2025.5.10)\n",
            "Requirement already satisfied: packaging>=21 in ./.venv/lib/python3.10/site-packages (from scikit-image) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in ./.venv/lib/python3.10/site-packages (from scikit-image) (0.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: imutils in ./.venv/lib/python3.10/site-packages (0.5.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: opencv-python in ./.venv/lib/python3.10/site-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in ./.venv/lib/python3.10/site-packages (from opencv-python) (2.1.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting xgboost\n",
            "  Downloading xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from xgboost) (2.1.3)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost)\n",
            "  Downloading nvidia_nccl_cu12-2.27.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: scipy in ./.venv/lib/python3.10/site-packages (from xgboost) (1.15.3)\n",
            "Downloading xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl (253.9 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 MB\u001b[0m \u001b[31m122.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.5 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 MB\u001b[0m \u001b[31m174.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [xgboost]━━━\u001b[0m \u001b[32m1/2\u001b[0m [xgboost]\n",
            "\u001b[1A\u001b[2KSuccessfully installed nvidia-nccl-cu12-2.27.6 xgboost-3.0.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install numpy\n",
        "%pip install tensorflow\n",
        "%pip install scikit-learn\n",
        "%pip install matplotlib\n",
        "%pip install scikit-image\n",
        "%pip install imutils\n",
        "%pip install opencv-python\n",
        "%pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S0U53F9ye0FW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-18 16:05:16.846521: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-07-18 16:05:16.879468: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-07-18 16:05:17.152876: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-07-18 16:05:17.381358: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752865517.560687  166317 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752865517.612239  166317 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1752865518.083807  166317 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1752865518.083841  166317 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1752865518.083844  166317 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1752865518.083846  166317 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-07-18 16:05:18.132385: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import math\n",
        "from skimage import feature\n",
        "from skimage.feature import hog\n",
        "from imutils import paths\n",
        "#from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, GlobalMaxPooling2D\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, RandomFlip, RandomRotation, RandomZoom\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import regularizers, Input\n",
        "from keras.models import Model, load_model\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cnn(input_shape=(32,32,3), num_classes=10, pool='flatten'):\n",
        "  model = Sequential()\n",
        "\n",
        "  #  CNN em “três estágios” de convolução + pooling para extrair \n",
        "  # representações progressivamente mais abstratas, e em seguida camadas \n",
        "  # densas para mapear essas representações em classificações.\n",
        "\n",
        "  # blocos 1, 2, 3 para aprendizado da representacao\n",
        "\n",
        "  # 1\n",
        "  # Conv2D(32, (3,3), …): aprende 32 filtros 3×3 sobre a entrada; \n",
        "  # padding='same' mantém as dimensões espaciais (32×32).\n",
        "  # activation='relu': aplica ReLU, que ajuda a modelar não-linearidades.\n",
        "  # Dropout(0.3): “desliga” aleatoriamente 30% dos neurônios para evitar overfitting.\n",
        "  # MaxPooling2D(2×2): reduz pela metade altura e largura (e.g. de 32×32 para 16×16), mantendo o filtro mais forte em cada região.\n",
        "  \n",
        "  model.add(Conv2D(32, (3,3), padding='same'\n",
        "                      , input_shape=input_shape\n",
        "                      , kernel_regularizer=tf.keras.regularizers.l2(1e-4)))\n",
        "  \n",
        "  # BatchNormalization() após cada convolução, antes da ReLU: \n",
        "  # estabiliza a distribuição das ativações, acelera e regulariza o treino.\n",
        "  model.add(BatchNormalization())\n",
        "  # Activation('relu') separada da Conv2D, seguindo o padrão Conv→BN→ReLU.\n",
        "  model.add(Activation('relu'))\n",
        "  \n",
        "  model.add(Conv2D(32, (3,3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  # 2\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  # 3\n",
        "  model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  # camadas densas\n",
        "  # parte totalmente conectada\n",
        "  # Flatten(): “desenrola” o volume de ativação (por exemplo, 4×4×128 → 2048 neurônios).\n",
        "  # GlobalMaxPooling2D(): toma o máximo de cada mapa de ativação, resultando em 128 valores fixos (um por filtro), independente da dimensão espacial.\n",
        "  if pool == 'flatten': model.add(Flatten())\n",
        "  else: model.add(GlobalMaxPooling2D())\n",
        "  \n",
        "  # Dense(512, relu): camada oculta com 512 neurônios para aprender combinações de características extraídas.\n",
        "  model.add(Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(num_classes, activation='softmax',))\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "fp_weights = './checkpoints/bestmodel_cnn_basica_global_nadam.keras'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cfJaQMYfmHw",
        "outputId": "da6d2f64-94d4-411c-caf7-e135c2c7388b"
      },
      "outputs": [],
      "source": [
        "# 2) Carregue os dados CIFAR‑10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "# normalize para [0,1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test  = x_test .astype('float32') / 255.0\n",
        "# achate os labels para vetor 1D\n",
        "y_train = y_train.ravel()\n",
        "y_test  = y_test.ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/philipe.hfransozi/Downloads/atividade_3/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "2025-07-18 10:53:35.644950: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
          ]
        }
      ],
      "source": [
        "model_cnn = cnn(input_shape=(32,32,3), num_classes=10, pool='global')\n",
        "model_cnn.load_weights(fp_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn_extractor = Sequential(model_cnn.layers[:-2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train_cnn \u001b[38;5;241m=\u001b[39m \u001b[43mcnn_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m X_test_cnn  \u001b[38;5;241m=\u001b[39m cnn_extractor\u001b[38;5;241m.\u001b[39mpredict(x_test,  batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m~/Downloads/atividade_3/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/Downloads/atividade_3/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:566\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    564\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m    565\u001b[0m data \u001b[38;5;241m=\u001b[39m get_data(iterator)\n\u001b[0;32m--> 566\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m outputs \u001b[38;5;241m=\u001b[39m append_to_outputs(batch_outputs, outputs)\n\u001b[1;32m    568\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_end(step, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_outputs})\n",
            "File \u001b[0;32m~/Downloads/atividade_3/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/Downloads/atividade_3/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/Downloads/atividade_3/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[1;32m    914\u001b[0m   filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    915\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(\n\u001b[1;32m    916\u001b[0m           bound_args\n\u001b[1;32m    917\u001b[0m       )\n\u001b[1;32m    918\u001b[0m   )\n\u001b[0;32m--> 919\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    920\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds):\n\u001b[1;32m    925\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m~/Downloads/atividade_3/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/Downloads/atividade_3/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[0;32m~/Downloads/atividade_3/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
            "File \u001b[0;32m~/Downloads/atividade_3/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
            "File \u001b[0;32m~/Downloads/atividade_3/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "X_train_cnn = cnn_extractor.predict(x_train, batch_size=64, verbose=1)\n",
        "X_test_cnn  = cnn_extractor.predict(x_test,  batch_size=64, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape dos features (train): (50000, 512)\n",
            "Shape dos features (test) : (10000, 512)\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape dos features (train):\", X_train_cnn.shape)  # (50000, 512)\n",
        "print(\"Shape dos features (test) :\", X_test_cnn.shape)   # (10000, 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_train = tf.data.Dataset.from_tensor_slices(x_train)\n",
        "ds_test = tf.data.Dataset.from_tensor_slices(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "W, H = 224, 224\n",
        "def _pre(img):\n",
        "    img = tf.image.resize(img, [W, H])\n",
        "    img = preprocess_input(img)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "ds_train = ds_train.map(_pre, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.map(_pre, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 405ms/step\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 404ms/step\n",
            "X_train_feats.shape: (50000, 1280)\n",
            "X_test_feats.shape : (10000, 1280)\n"
          ]
        }
      ],
      "source": [
        "mnet = MobileNetV2(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    pooling='avg',\n",
        "    input_shape=(W, H, 3)\n",
        ")\n",
        "\n",
        "X_train_netv2 = mnet.predict(ds_train, batch_size=64, verbose=1)\n",
        "X_test_netv2  = mnet.predict(ds_test,  batch_size=64, verbose=1)\n",
        "\n",
        "print(\"X_train_feats.shape:\", X_train_netv2.shape)  # (50000,1280)\n",
        "print(\"X_test_feats.shape :\", X_test_netv2.shape)   # (10000,1280)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import (\n",
        "    ResNet50, InceptionV3, Xception,\n",
        "    resnet50, inception_v3, xception\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_feature_extractor(model_name='resnet50'):\n",
        "    if model_name == 'resnet50':\n",
        "        ModelClass    = ResNet50\n",
        "        preprocess_fn = resnet50.preprocess_input\n",
        "        target_size   = (224, 224)\n",
        "    elif model_name == 'inceptionv3':\n",
        "        ModelClass    = InceptionV3\n",
        "        preprocess_fn = inception_v3.preprocess_input\n",
        "        target_size   = (299, 299)\n",
        "    elif model_name == 'xception':\n",
        "        ModelClass    = Xception\n",
        "        preprocess_fn = xception.preprocess_input\n",
        "        target_size   = (299, 299)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model {model_name}\")\n",
        "\n",
        "    base = ModelClass(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        pooling='avg',\n",
        "        input_shape=(*target_size, 3)\n",
        "    )\n",
        "    return base, preprocess_fn, target_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cria o tf.data pipeline que faz resize + preprocess_input certo\n",
        "def make_dataset(x, batch_size=64):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(x)\n",
        "    def _prep(img):\n",
        "        img = tf.image.resize(img, [W, H])\n",
        "        img = preprocess_fn(img)\n",
        "        return img\n",
        "    return ds.map(_prep, num_parallel_calls=tf.data.AUTOTUNE) \\\n",
        "             .batch(batch_size) \\\n",
        "             .prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-18 16:06:57.294469: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
          ]
        }
      ],
      "source": [
        "backbone, preprocess_fn, (W, H) = make_feature_extractor('inceptionv3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1647s\u001b[0m 2s/step\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 2s/step\n"
          ]
        }
      ],
      "source": [
        "ds_train_inceptionv3 = make_dataset(x_train)\n",
        "ds_test_inceptionv3  = make_dataset(x_test)\n",
        "\n",
        "# Extrai features sem encher a RAM\n",
        "X_train_inceptionv3 = backbone.predict(ds_train_inceptionv3, verbose=1)\n",
        "X_test_inceptionv3  = backbone.predict(ds_test_inceptionv3,  verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1998s\u001b[0m 3s/step\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m476s\u001b[0m 3s/step\n"
          ]
        }
      ],
      "source": [
        "backbone, preprocess_fn, (W, H) = make_feature_extractor('xception')\n",
        "ds_train_xception = make_dataset(x_train)\n",
        "ds_test_xception  = make_dataset(x_test)\n",
        "\n",
        "# Extrai features sem encher a RAM\n",
        "X_train_xception = backbone.predict(ds_train_xception, verbose=1)\n",
        "X_test_xception  = backbone.predict(ds_test_xception,  verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m832s\u001b[0m 1s/step\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step\n"
          ]
        }
      ],
      "source": [
        "backbone, preprocess_fn, (W, H) = make_feature_extractor()\n",
        "ds_train_resnet50 = make_dataset(x_train)\n",
        "ds_test_resnet50  = make_dataset(x_test)\n",
        "\n",
        "# Extrai features sem encher a RAM\n",
        "X_train_resnet50 = backbone.predict(ds_train_resnet50, verbose=1)\n",
        "X_test_resnet50  = backbone.predict(ds_test_resnet50,  verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1) Definição dos pipelines base\n",
        "pipelines = {\n",
        "    # 'SVC': Pipeline([\n",
        "    #     ('scaler', StandardScaler()),\n",
        "    #     ('pca', PCA()),\n",
        "    #     ('clf', SVC(probability=True))\n",
        "    # ]),\n",
        "    'RandomForest': Pipeline([\n",
        "        ('scaler', StandardScaler()), \n",
        "        ('pca',     PCA()),\n",
        "        ('clf', RandomForestClassifier(random_state=42))\n",
        "    ]),\n",
        "    'MLPClassifier': Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('pca',     PCA()),\n",
        "        ('clf', MLPClassifier(random_state=42, max_iter=250))\n",
        "    ]),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2) Grades de parâmetros para cada um\n",
        "param_grids = {\n",
        "    # 'SVC': {\n",
        "    #     'clf__C': [1, 5, 10],\n",
        "    #     'clf__gamma': [0.001, 0.0001, 'scale'],\n",
        "    #     'clf__kernel': ['rbf', 'linear']\n",
        "    # },\n",
        "    'RandomForest': {\n",
        "        'clf__n_estimators': [100, 200, 500],\n",
        "        'clf__max_depth': [None, 10, 20],\n",
        "        'clf__min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'MLPClassifier': {\n",
        "        'clf__hidden_layer_sizes': [(256,), (512,)],\n",
        "        'clf__alpha': [1e-4, 1e-3, 1e-2],\n",
        "        'clf__learning_rate_init': [1e-3, 1e-4],\n",
        "        'clf__activation':['relu', 'logistic']\n",
        "    }\n",
        "}\n",
        "\n",
        "param_grids_pca = {\n",
        "    **param_grids,  # preserva os grids de clf__*\n",
        "    **{            # adiciona pca__n_components para **todos** os pipelines\n",
        "        name: {\n",
        "            **params,\n",
        "            'pca__n_components': [300]\n",
        "        }\n",
        "        for name, params in param_grids.items()\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "def classificacao(X_train, X_test, y_train, y_test, param_grids, pipelines):\n",
        "    # 1) Busca dos melhores estimadores\n",
        "    best_estimators = {}\n",
        "    for name, pipe in pipelines.items():\n",
        "        print(f\"\\n--- Tuning {name} ---\")\n",
        "        grid = GridSearchCV(\n",
        "            pipe,\n",
        "            param_grid=param_grids[name],\n",
        "            cv=3,\n",
        "            scoring='accuracy',\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        grid.fit(X_train, y_train)\n",
        "        print(f\"Best params for {name}: {grid.best_params_}\")\n",
        "        print(f\"Best CV accuracy for {name}: {grid.best_score_:.4f}\")\n",
        "        best_estimators[name] = grid.best_estimator_\n",
        "\n",
        "    # 2) Avaliação no conjunto de teste\n",
        "    resultados = []\n",
        "    for name, est in best_estimators.items():\n",
        "        y_pred = est.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        cm  = confusion_matrix(y_test, y_pred)\n",
        "        \n",
        "        # Armazena para o resumo\n",
        "        resultados.append({\n",
        "            'Modelo': name,\n",
        "            'Acurácia': acc,\n",
        "            'Matriz de Confusão': cm\n",
        "        })\n",
        "        \n",
        "    # 3) Exibe tabela resumo (sem imprimir a matrix inteira na célula)\n",
        "    df_resumo = pd.DataFrame(resultados)\n",
        "    # Mostra as duas primeiras colunas\n",
        "    print(\"\\n=== Resumo de Acurácias ===\")\n",
        "    print(df_resumo[['Modelo','Acurácia']].to_string(index=False))\n",
        "\n",
        "    # 4) Exibe cada matriz de confusão detalhadamente\n",
        "    for row in resultados:\n",
        "        name = row['Modelo']\n",
        "        cm   = row['Matriz de Confusão']\n",
        "        print(f\"\\nMatriz de Confusão para {name}:\")\n",
        "        print(pd.DataFrame(\n",
        "            cm,\n",
        "            index=[f\"True_{i}\" for i in range(cm.shape[0])],\n",
        "            columns=[f\"Pred_{i}\" for i in range(cm.shape[1])]\n",
        "        ).to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classificacao(X_train_cnn, X_test_cnn, y_train, y_test, param_grids_pca, pipelines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classificacao(X_train_netv2, X_test_netv2, y_train, y_test, param_grids_pca, pipelines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classificacao(X_train_inceptionv3, X_test_inceptionv3, y_train, y_test, param_grids_pca, pipelines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classificacao(X_train_xception, X_test_xception, y_train, y_test, param_grids_pca, pipelines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classificacao(X_train_resnet50, X_test_resnet50, y_train, y_test, param_grids_pca, pipelines)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
