{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e37deb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications, callbacks\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Removido data augmentation nesta etapa\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ed61195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "def plot_confusion(cm, labels, title=None):\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "    disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdeee77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    # Normalização ao intervalo [0,1]\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_test  = x_test.astype('float32') / 255.0\n",
    "    # One-hot para treino/fine-tuning\n",
    "    y_train_cat = tf.keras.utils.to_categorical(y_train, 10)\n",
    "    y_test_cat  = tf.keras.utils.to_categorical(y_test, 10)\n",
    "    # Labels achatadas para classifier raso\n",
    "    y_train_lbl = y_train.flatten()\n",
    "    y_test_lbl  = y_test.flatten()\n",
    "    return x_train, y_train_cat, y_train_lbl, x_test, y_test_cat, y_test_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab764ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar10_dataset(batch_size=64, buffer_size=5000):\n",
    "    # Carrega dados\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    # Normalização\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_test  = x_test.astype('float32') / 255.0\n",
    "    # One-hot labels\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, 10).astype('float32')\n",
    "    y_test  = tf.keras.utils.to_categorical(y_test, 10).astype('float32')\n",
    "\n",
    "    # Cria datasets\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_ds = train_ds.shuffle(buffer_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    test_ds = test_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b24f6fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_scratch(input_shape=(32, 32, 3), num_classes=10):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    return models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a20aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn_scratch():\n",
    "    # Carrega arrays numpy e datasets\n",
    "    x_train, y_train_cat, _, x_test, y_test_cat, _ = load_data()\n",
    "    train_ds, test_ds = get_cifar10_dataset()\n",
    "\n",
    "    # Constrói e compila o modelo\n",
    "    model = build_cnn_scratch()\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Early stopping\n",
    "    early = callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    # Treina usando tf.data\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=30,\n",
    "        validation_data=test_ds,\n",
    "        callbacks=[early],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # Avaliação\n",
    "    loss, acc = model.evaluate(test_ds, verbose=0)\n",
    "    print(f\"CNN do zero: Test accuracy = {acc:.4f}\")\n",
    "\n",
    "    # Matriz de Confusão via arrays numpy (evita iterator esgotado)\n",
    "    y_true = y_test_cat.argmax(axis=1)\n",
    "    y_pred = model.predict(x_test).argmax(axis=1)\n",
    "    class_names = ['airplane','automobile','bird','cat','deer',\n",
    "                   'dog','frog','horse','ship','truck']\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plot_confusion(cm, class_names, title='Confusion - CNN from Scratch')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "498df64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_finetune_model(backbone='ResNet50',\n",
    "                         input_shape=(32,32,3),\n",
    "                         num_classes=10,\n",
    "                         unfreeze_from=140):\n",
    "    # carrega a base pré-treinada sem o top\n",
    "    if backbone == 'VGG16':\n",
    "        base = applications.VGG16(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "    )\n",
    "    elif backbone == 'MobileNetV2':\n",
    "        base = applications.MobileNetV2(\n",
    "            weights='imagenet', include_top=False,\n",
    "            input_shape=input_shape)\n",
    "    else:\n",
    "        base = applications.ResNet50(\n",
    "            weights='imagenet', include_top=False,\n",
    "            input_shape=input_shape)\n",
    "\n",
    "    # congela tudo\n",
    "    for layer in base.layers:\n",
    "        layer.trainable = False\n",
    "    # descongela só as últimas\n",
    "    for layer in base.layers[unfreeze_from:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(256, activation='relu',\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    return models.Model(inputs=base.input, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b01248e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fine_tuning(x_train, y_train_cat, x_test, y_test_cat,\n",
    "                      backbone='ResNet50',\n",
    "                      unfreeze_from=140,\n",
    "                      epochs=20,\n",
    "                      batch_size=64):\n",
    "    \n",
    "    model = build_finetune_model(backbone, unfreeze_from=unfreeze_from)\n",
    "    opt = Adam(learning_rate=1e-4)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    # early = callbacks.EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "    early = callbacks.EarlyStopping(monitor='val_accuracy', patience=13, restore_best_weights=True)\n",
    "    \n",
    "    \n",
    "    history = model.fit(\n",
    "        x_train, y_train_cat,\n",
    "        validation_data=(x_test, y_test_cat),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early],\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    loss, acc = model.evaluate(x_test, y_test_cat, verbose=0)\n",
    "    print(f\"Fine-tune {backbone}: Test accuracy = {acc:.4f}\")\n",
    "\n",
    "    # plot matriz de confusão\n",
    "    y_pred = model.predict(x_test).argmax(axis=1)\n",
    "    y_true = y_test_cat.argmax(axis=1)\n",
    "    class_names = ['airplane','automobile','bird','cat','deer',\n",
    "                   'dog','frog','horse','ship','truck']\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plot_confusion(cm, class_names,\n",
    "                   title=f\"Confusion – Fine-tune {backbone}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feee56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina apenas a CNN do zero com tf.data.Dataset\n",
    "train_cnn_scratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ae1130",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train_cat, _, x_test, y_test_cat, _ = load_data()\n",
    "ft_model = train_fine_tuning(\n",
    "    x_train, y_train_cat, x_test, y_test_cat,\n",
    "    backbone='ResNet50',\n",
    "    unfreeze_from=160,\n",
    "    epochs=30,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d741deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train_cat, _, x_test, y_test_cat, _ = load_data()\n",
    "ft_model = train_fine_tuning(\n",
    "    x_train, y_train_cat, x_test, y_test_cat,\n",
    "    backbone='VGG16',\n",
    "    unfreeze_from=160,\n",
    "    epochs=30,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf975e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train_cat, _, x_test, y_test_cat, _ = load_data()\n",
    "ft_model = train_fine_tuning(\n",
    "    x_train, y_train_cat, x_test, y_test_cat,\n",
    "    backbone='MobileNetV2',\n",
    "    unfreeze_from=160,\n",
    "    epochs=30,\n",
    "    batch_size=64\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
